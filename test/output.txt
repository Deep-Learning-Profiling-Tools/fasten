============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-7.4.0, pluggy-1.2.0
rootdir: /home/kganapa/fasten
collected 896 items

test_ops.py ..s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [  6%]
s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s. [ 14%]
..s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [ 22%]
s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s. [ 30%]
..s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [ 38%]
s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s. [ 46%]
..s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [ 54%]
s.s...s..Fs.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s. [ 62%]
..s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [ 70%]
s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s. [ 79%]
..s.s.s.s.s...s..FsFsFsFsFsF..s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s. [ 87%]
s.s...s...s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s...s..FsFsFs.sFs...s. [ 95%]
..s.s.s.s.s...s...s.s.s.s.s...s...s.s.s.s.s.                             [100%]

=================================== FAILURES ===================================
____ test_segment_matmul[64-16-slices3-float32-backward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
        [ -4.8828, -11.2666,  -4.7832,  .....      [  6.5631, -15.4653,  -5.0441,  ...,  11.5364,  10.2327,  -8.4684]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
        [ -4.8828, -11.2666,  -4.7832,  ..... -5.0441,  ...,  11.5364,  10.2327,  -8.4684]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.59 GiB (GPU 0; 23.64 GiB total capacity; 14.54 GiB already allocated; 1.34 GiB free; 15.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 64, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'backward'
dtype = torch.float32

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
E                   [ -4.8828, -11.2666,  -4.7832,  ..., -15.3027, -11.5216, -10.5906],
E                   [-10.8610,  -2.3075,   8.9187,  ...,   3.6163,  -0.5615,  -2.7137],
E                   ...,
E                   [ -5.3720,  -6.5745,   2.2852,  ...,   6.9483,   3.4319,  -3.1003],
E                   [  9.0667,   6.2400, -12.4546,  ...,   7.6214, -10.8125,   0.0919],
E                   [  6.5631, -15.4653,  -5.0441,  ...,  11.5364,  10.2327,  -8.4684]],
E                  device='cuda:0'),
E               expected=tensor([[-14.0087,  15.1672,   7.1829,  ...,  14.1854,  -0.2773,  -9.0586],
E                   [ -4.8828, -11.2666,  -4.7832,  ..., -15.3027, -11.5216, -10.5906],
E                   [-10.8610,  -2.3075,   8.9187,  ...,   3.6163,  -0.5615,  -2.7137],
E                   ...,
E                   [ -5.3720,  -6.5745,   2.2852,  ...,   6.9483,   3.4319,  -3.1003],
E                   [  9.0667,   6.2400, -12.4546,  ...,   7.6214, -10.8125,   0.0919],
E                   [  6.5631, -15.4653,  -5.0441,  ...,  11.5364,  10.2327,  -8.4684]],
E                  device='cuda:0', grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
____ test_segment_matmul[80-16-slices3-float32-backward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
        [  1.3563,  -7.2062,   7.1154,  .....      [ 19.4850,   2.4042,  13.2721,  ...,  -0.8856, -14.6271,   2.9373]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
        [  1.3563,  -7.2062,   7.1154,  ..... 13.2721,  ...,  -0.8856, -14.6271,   2.9373]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 14.19 GiB already allocated; 355.38 MiB free; 16.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'backward'
dtype = torch.float32

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
E                   [  1.3563,  -7.2062,   7.1154,  ...,   6.6296,  -4.2436,  -6.3645],
E                   [  1.3729,  11.7747,   5.8923,  ..., -13.9060,   2.0531,   5.7260],
E                   ...,
E                   [  5.5927,   3.5484,  -3.8128,  ...,   8.8136,  -4.0674, -19.5129],
E                   [-28.8222,   9.4829,  -4.0743,  ...,  -2.0164,  -2.5908,  14.7118],
E                   [ 19.4850,   2.4042,  13.2721,  ...,  -0.8856, -14.6271,   2.9373]],
E                  device='cuda:0'),
E               expected=tensor([[  2.1506,  15.5609,   1.1578,  ...,  -2.3971,  -4.8798,   3.7696],
E                   [  1.3563,  -7.2062,   7.1154,  ...,   6.6296,  -4.2436,  -6.3645],
E                   [  1.3729,  11.7747,   5.8923,  ..., -13.9060,   2.0531,   5.7260],
E                   ...,
E                   [  5.5927,   3.5484,  -3.8128,  ...,   8.8136,  -4.0674, -19.5129],
E                   [-28.8222,   9.4829,  -4.0743,  ...,  -2.0164,  -2.5908,  14.7118],
E                   [ 19.4850,   2.4042,  13.2721,  ...,  -0.8856, -14.6271,   2.9373]],
E                  device='cuda:0', grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
____ test_segment_matmul[80-16-slices3-float32-backward-Engine.TRITON-cuda] ____

self = TensorLikePair(
    id=(),
    actual=tensor([[ 14.6164,  -4.7544,  -1.6590,  ...,  13.5857, -11.2495,   0.1463],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[ 14.6164,  -4.7544,  -1.6590,  ...,  13.5857, -11.2495,   0.1463],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[ 14.6164,  -4.7544,  -1.6590,  ...,  13.5857, -11.2495,   0.1463],
        [ 15.4661,  14.1428,   3.8787,  .....      [ -8.4850,   2.9560,  -4.1111,  ...,  -1.8372,  -2.2172,   7.2055]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[ 14.6245,  -4.7621,  -1.6601,  ...,  13.5938, -11.2584,   0.1453],
        [ 15.4678,  14.1533,   3.8814,  ..... -4.1189,  ...,  -1.8389,  -2.2150,   7.2055]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 13.18 GiB already allocated; 421.38 MiB free; 16.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TRITON: 'triton'>, device = 'cuda', phase = 'backward'
dtype = torch.float32

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[ 14.6164,  -4.7544,  -1.6590,  ...,  13.5857, -11.2495,   0.1463],
E                   [ 15.4661,  14.1428,   3.8787,  ...,  -0.3381,  13.8355, -18.7012],
E                   [  7.7679,   3.5860,   2.6989,  ...,   3.3752,  -8.3757,  15.1290],
E                   ...,
E                   [ -0.8887,  16.0827,  -6.0472,  ...,   0.2920,  -4.8524,   2.1183],
E                   [  7.0955,   3.1342,  -6.3895,  ...,   1.3077,   8.2134,  -8.8139],
E                   [ -8.4850,   2.9560,  -4.1111,  ...,  -1.8372,  -2.2172,   7.2055]],
E                  device='cuda:0'),
E               expected=tensor([[ 14.6245,  -4.7621,  -1.6601,  ...,  13.5938, -11.2584,   0.1453],
E                   [ 15.4678,  14.1533,   3.8814,  ...,  -0.3408,  13.8432, -18.7086],
E                   [  7.7729,   3.5938,   2.6970,  ...,   3.3740,  -8.3823,  15.1423],
E                   ...,
E                   [ -0.8915,  16.0952,  -6.0519,  ...,   0.2847,  -4.8617,   2.1207],
E                   [  7.1007,   3.1380,  -6.3925,  ...,   1.3070,   8.2200,  -8.8219],
E                   [ -8.4932,   2.9579,  -4.1189,  ...,  -1.8389,  -2.2150,   7.2055]],
E                  device='cuda:0', grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
_____ test_segment_matmul[80-16-slices3-float16-forward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:993: in _compare_regular_values_close
    actual, expected = self._promote_for_comparison(actual, expected)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
        [ -1.0273,   3.2129,  -0.3076,  .....      [-15.4453,   3.6973,   5.8672,  ...,  -2.9238, -16.7969,  -3.3145]],
       device='cuda:0', dtype=torch.float16)
expected = tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
        [ -1.0273,   3.2129,  -0.3076,  .....      [-15.4453,   3.6973,   5.8672,  ...,  -2.9238, -16.7969,  -3.3145]],
       device='cuda:0', dtype=torch.float16)

    def _promote_for_comparison(
        self, actual: torch.Tensor, expected: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """Promotes the inputs to the comparison dtype based on the input dtype.

        Returns:
            Inputs promoted to the highest precision dtype of the same dtype category. :class:`torch.bool` is treated
            as integral dtype.
        """
        # This is called after self._equalize_attributes() and thus `actual` and `expected` already have the same dtype.
        if actual.dtype.is_complex:
            dtype = torch.complex128
        elif actual.dtype.is_floating_point:
            dtype = torch.float64
        else:
            dtype = torch.int64
>       return actual.to(dtype), expected.to(dtype)
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 14.94 GiB already allocated; 421.38 MiB free; 16.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:1030: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'forward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
>           torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
E                   [ -1.0273,   3.2129,  -0.3076,  ..., -11.9062,   1.6895,   9.0000],
E                   [  4.6484,  15.2031,  -0.1750,  ...,  12.5234,   0.6797, -13.0000],
E                   ...,
E                   [  6.0195,   9.4844,  -9.2344,  ...,  -7.0039,  14.7344, -11.6719],
E                   [  7.9297,   4.1016,  -8.5625,  ...,  14.7969,  -8.8203,   9.9609],
E                   [-15.4453,   3.6973,   5.8672,  ...,  -2.9238, -16.7969,  -3.3145]],
E                  device='cuda:0', dtype=torch.float16),
E               expected=tensor([[  2.2441,   1.4795,  -1.7441,  ...,  -1.9355,  17.8125,  16.4375],
E                   [ -1.0273,   3.2129,  -0.3076,  ..., -11.9062,   1.6895,   9.0000],
E                   [  4.6484,  15.2031,  -0.1750,  ...,  12.5234,   0.6797, -13.0000],
E                   ...,
E                   [  6.0195,   9.4844,  -9.2344,  ...,  -7.0039,  14.7344, -11.6719],
E                   [  7.9297,   4.1016,  -8.5625,  ...,  14.7969,  -8.8203,   9.9609],
E                   [-15.4453,   3.6973,   5.8672,  ...,  -2.9238, -16.7969,  -3.3145]],
E                  device='cuda:0', dtype=torch.float16),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:45: RuntimeError
____ test_segment_matmul[80-16-slices3-float16-forward-Engine.TRITON-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.9590,   8.7656,   6.8594,  ...,  -9.6875,   5.5938,  15.2656],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[  2.9590,   8.7656,   6.8594,  ...,  -9.6875,   5.5938,  15.2656],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[  2.9590,   8.7656,   6.8594,  ...,  -9.6875,   5.5938,  15.2656],
        [ -8.4297, -15.4219,  -5.6836,  .....      [  8.3984,   1.6758,   2.4805,  ..., -20.1562,   3.9453,   2.1582]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[  2.9551,   8.7656,   6.8594,  ...,  -9.6797,   5.5898,  15.2656],
        [ -8.4297, -15.4141,  -5.6875,  .....      [  8.3906,   1.6748,   2.4785,  ..., -20.1562,   3.9414,   2.1562]],
       device='cuda:0', dtype=torch.float64)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 13.18 GiB already allocated; 1.30 GiB free; 15.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TRITON: 'triton'>, device = 'cuda', phase = 'forward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
>           torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[  2.9590,   8.7656,   6.8594,  ...,  -9.6875,   5.5938,  15.2656],
E                   [ -8.4297, -15.4219,  -5.6836,  ..., -15.2344,   7.5156,   0.3518],
E                   [ 16.9531,   0.1550,  18.7344,  ...,   6.5391,   3.3926,  -6.4609],
E                   ...,
E                   [  4.2891,   2.0938,   2.4922,  ...,   6.4609,   0.9380,   2.6582],
E                   [ 17.4844,  -6.6406,  10.7734,  ...,   0.8691,  14.5469,   3.3496],
E                   [  8.3984,   1.6758,   2.4805,  ..., -20.1562,   3.9453,   2.1582]],
E                  device='cuda:0', dtype=torch.float16),
E               expected=tensor([[  2.9551,   8.7656,   6.8594,  ...,  -9.6797,   5.5898,  15.2656],
E                   [ -8.4297, -15.4141,  -5.6875,  ..., -15.2344,   7.5195,   0.3540],
E                   [ 16.9531,   0.1533,  18.7344,  ...,   6.5391,   3.3887,  -6.4570],
E                   ...,
E                   [  4.2891,   2.0977,   2.4902,  ...,   6.4609,   0.9395,   2.6582],
E                   [ 17.4688,  -6.6445,  10.7734,  ...,   0.8687,  14.5469,   3.3516],
E                   [  8.3906,   1.6748,   2.4785,  ..., -20.1562,   3.9414,   2.1562]],
E                  device='cuda:0', dtype=torch.float16),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:45: RuntimeError
____ test_segment_matmul[80-16-slices3-float16-backward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
          7.2...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:993: in _compare_regular_values_close
    actual, expected = self._promote_for_comparison(actual, expected)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
          7.2...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
          7.2109e+00, -9.6406e+00],
        [-2.898... 4.5117e+00,  2.5031e+01,  ..., -5.8750e+00,
         -2.1914e+00, -7.3789e+00]], device='cuda:0', dtype=torch.float16)
expected = tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
          7.2109e+00, -9.6406e+00],
        [-2.898...., -5.8750e+00,
         -2.1914e+00, -7.3789e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<CopySlices>)

    def _promote_for_comparison(
        self, actual: torch.Tensor, expected: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """Promotes the inputs to the comparison dtype based on the input dtype.

        Returns:
            Inputs promoted to the highest precision dtype of the same dtype category. :class:`torch.bool` is treated
            as integral dtype.
        """
        # This is called after self._equalize_attributes() and thus `actual` and `expected` already have the same dtype.
        if actual.dtype.is_complex:
            dtype = torch.complex128
        elif actual.dtype.is_floating_point:
            dtype = torch.float64
        else:
            dtype = torch.int64
>       return actual.to(dtype), expected.to(dtype)
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 13.95 GiB already allocated; 1.30 GiB free; 15.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:1030: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'backward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
E                     7.2109e+00, -9.6406e+00],
E                   [-2.8984e+00,  8.1328e+00, -1.6219e+01,  ...,  2.7578e+00,
E                     4.5117e+00, -1.0516e+01],
E                   [-8.4609e+00, -1.0273e+00,  1.3242e+01,  ...,  3.2695e+00,
E                    -1.8818e+00,  3.9785e+00],
E                   ...,
E                   [-6.5742e+00,  1.5039e+01, -1.0925e-01,  ..., -3.8848e+00,
E                     6.0272e-03,  1.2480e+00],
E                   [-2.2578e+00,  4.4922e+00,  2.3281e+00,  ..., -1.2219e+01,
E                     1.0570e+01, -3.2266e+00],
E                   [-9.2383e-01,  4.5117e+00,  2.5031e+01,  ..., -5.8750e+00,
E                    -2.1914e+00, -7.3789e+00]], device='cuda:0', dtype=torch.float16),
E               expected=tensor([[ 1.0852e+01,  9.0137e-01,  7.2344e+00,  ...,  1.0086e+01,
E                     7.2109e+00, -9.6406e+00],
E                   [-2.8984e+00,  8.1328e+00, -1.6219e+01,  ...,  2.7578e+00,
E                     4.5117e+00, -1.0516e+01],
E                   [-8.4609e+00, -1.0273e+00,  1.3242e+01,  ...,  3.2695e+00,
E                    -1.8818e+00,  3.9785e+00],
E                   ...,
E                   [-6.5742e+00,  1.5039e+01, -1.0925e-01,  ..., -3.8848e+00,
E                     6.0272e-03,  1.2480e+00],
E                   [-2.2578e+00,  4.4922e+00,  2.3281e+00,  ..., -1.2219e+01,
E                     1.0570e+01, -3.2266e+00],
E                   [-9.2383e-01,  4.5117e+00,  2.5031e+01,  ..., -5.8750e+00,
E                    -2.1914e+00, -7.3789e+00]], device='cuda:0', dtype=torch.float16,
E                  grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
____ test_segment_matmul[80-16-slices3-float16-backward-Engine.TRITON-cuda] ____

self = TensorLikePair(
    id=(),
    actual=tensor([[  1.9209,  -8.1562,  -7.2461,  ...,  -7.0703,  -9.2891,   8.1484],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[  1.9209,  -8.1562,  -7.2461,  ...,  -7.0703,  -9.2891,   8.1484],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[  1.9209,  -8.1562,  -7.2461,  ...,  -7.0703,  -9.2891,   8.1484],
        [  0.0494,  -4.9180,  14.4141,  .....      [ 12.1875,  -7.9258,  10.3594,  ...,  -4.4453, -19.2500,  -9.5859]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[  1.9219,  -8.1562,  -7.2305,  ...,  -7.0664,  -9.2891,   8.1484],
        [  0.0496,  -4.9219,  14.4219,  ..... 10.3594,  ...,  -4.4375, -19.2500,  -9.5938]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 11.69 GiB already allocated; 1.30 GiB free; 15.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 16
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TRITON: 'triton'>, device = 'cuda', phase = 'backward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[  1.9209,  -8.1562,  -7.2461,  ...,  -7.0703,  -9.2891,   8.1484],
E                   [  0.0494,  -4.9180,  14.4141,  ...,   0.7163,   4.5469,  -1.2314],
E                   [-10.5859,   0.3755,  10.2500,  ...,   9.0625,   2.8398,  -4.8125],
E                   ...,
E                   [  5.2812,  -0.8887,   0.0762,  ..., -13.5078,   6.5820,  15.2031],
E                   [ 10.0938,   2.8223,   1.8848,  ..., -13.3672,  12.4766, -13.5234],
E                   [ 12.1875,  -7.9258,  10.3594,  ...,  -4.4453, -19.2500,  -9.5859]],
E                  device='cuda:0', dtype=torch.float16),
E               expected=tensor([[  1.9219,  -8.1562,  -7.2305,  ...,  -7.0664,  -9.2891,   8.1484],
E                   [  0.0496,  -4.9219,  14.4219,  ...,   0.7188,   4.5430,  -1.2334],
E                   [-10.5781,   0.3774,  10.2578,  ...,   9.0703,   2.8359,  -4.8164],
E                   ...,
E                   [  5.2773,  -0.8882,   0.0762,  ..., -13.5156,   6.5820,  15.1953],
E                   [ 10.0938,   2.8242,   1.8838,  ..., -13.3750,  12.4766, -13.5312],
E                   [ 12.1875,  -7.9258,  10.3594,  ...,  -4.4375, -19.2500,  -9.5938]],
E                  device='cuda:0', dtype=torch.float16, grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
____ test_segment_matmul[80-33-slices3-float32-backward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
        [ 15.0391,  14.2528,  -3.2528,  .....      [ -7.0101,  13.8020,   1.3205,  ...,  -9.5830,   7.8347,   5.1242]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
        [ 15.0391,  14.2528,  -3.2528,  .....  1.3205,  ...,  -9.5830,   7.8347,   5.1242]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 20.14 GiB already allocated; 33.38 MiB free; 21.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 33
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'backward'
dtype = torch.float32

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
E                   [ 15.0391,  14.2528,  -3.2528,  ...,  13.8722,  -4.5307,  -1.9265],
E                   [ -3.7020,  -0.0899,   2.2265,  ...,   3.3340,   6.9295,  15.4285],
E                   ...,
E                   [  2.7987,  -9.5956, -15.1093,  ...,  -9.1277,   5.2530,  -5.6084],
E                   [  2.2966,  11.2098,  -8.4251,  ...,   4.0775,  -4.2773,  15.1138],
E                   [ -7.0101,  13.8020,   1.3205,  ...,  -9.5830,   7.8347,   5.1242]],
E                  device='cuda:0'),
E               expected=tensor([[  4.2611,  -0.7476,  -7.9391,  ...,   4.1420,   0.7363,  -7.3767],
E                   [ 15.0391,  14.2528,  -3.2528,  ...,  13.8722,  -4.5307,  -1.9265],
E                   [ -3.7020,  -0.0899,   2.2265,  ...,   3.3340,   6.9295,  15.4285],
E                   ...,
E                   [  2.7987,  -9.5956, -15.1093,  ...,  -9.1277,   5.2530,  -5.6084],
E                   [  2.2966,  11.2098,  -8.4251,  ...,   4.0775,  -4.2773,  15.1138],
E                   [ -7.0101,  13.8020,   1.3205,  ...,  -9.5830,   7.8347,   5.1242]],
E                  device='cuda:0', grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
____ test_segment_matmul[80-33-slices3-float32-backward-Engine.TRITON-cuda] ____

self = TensorLikePair(
    id=(),
    actual=tensor([[-10.6754,   6.0992,  -4.1892,  ...,  -0.8560,  -4.0052,   5.7206],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[-10.6754,   6.0992,  -4.1892,  ...,  -0.8560,  -4.0052,   5.7206],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[-10.6754,   6.0992,  -4.1892,  ...,  -0.8560,  -4.0052,   5.7206],
        [  5.2509,  -1.1962,   2.1511,  .....      [ -2.6018,  -6.4942, -15.4495,  ...,   0.2594,  -4.1255,  13.1834]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[-10.6853,   6.1093,  -4.1928,  ...,  -0.8599,  -4.0055,   5.7225],
        [  5.2535,  -1.2076,   2.1497,  .....-15.4592,  ...,   0.2563,  -4.1293,  13.1921]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 19.13 GiB already allocated; 117.38 MiB free; 21.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 33
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TRITON: 'triton'>, device = 'cuda', phase = 'backward'
dtype = torch.float32

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[-10.6754,   6.0992,  -4.1892,  ...,  -0.8560,  -4.0052,   5.7206],
E                   [  5.2509,  -1.1962,   2.1511,  ...,   8.4183,   1.4771,  -4.9791],
E                   [  0.9353,   6.2660, -19.9080,  ...,   0.2123,   9.8142,  -1.7833],
E                   ...,
E                   [  8.4258,  -8.9004,   2.9890,  ...,   5.5548,  -8.2773,  -0.4185],
E                   [-12.9202,   7.6020, -12.3752,  ...,  -8.6435,   1.2138,  -4.3819],
E                   [ -2.6018,  -6.4942, -15.4495,  ...,   0.2594,  -4.1255,  13.1834]],
E                  device='cuda:0'),
E               expected=tensor([[-10.6853,   6.1093,  -4.1928,  ...,  -0.8599,  -4.0055,   5.7225],
E                   [  5.2535,  -1.2076,   2.1497,  ...,   8.4218,   1.4836,  -4.9836],
E                   [  0.9346,   6.2720, -19.9153,  ...,   0.2084,   9.8128,  -1.7841],
E                   ...,
E                   [  8.4344,  -8.9061,   2.9898,  ...,   5.5577,  -8.2809,  -0.4197],
E                   [-12.9255,   7.6092, -12.3849,  ...,  -8.6514,   1.2142,  -4.3862],
E                   [ -2.6067,  -6.4985, -15.4592,  ...,   0.2563,  -4.1293,  13.1921]],
E                  device='cuda:0', grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
_____ test_segment_matmul[80-33-slices3-float16-forward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
        [ -4.4180, -16.3750,  14.4219,  .....      [-13.0625, -11.0312,   1.1104,  ...,   6.7070, -14.6406,   6.0664]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
        [ -4.4180, -16.3750,  14.4219,  .....      [-13.0625, -11.0312,   1.1104,  ...,   6.7070, -14.6406,   6.0664]],
       device='cuda:0', dtype=torch.float64)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 19.15 GiB already allocated; 1.87 GiB free; 21.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 33
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'forward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
>           torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
E                   [ -4.4180, -16.3750,  14.4219,  ...,  -6.1055,   8.9141,  -1.5869],
E                   [ -2.9941,  -5.8555,  -0.9629,  ...,  -8.0859,   3.9727,  -4.7578],
E                   ...,
E                   [ 10.6641, -11.0547,   4.5977,  ...,   7.0039,   7.5508,  -7.2461],
E                   [ 13.4688,  10.2422,  -4.3711,  ...,  -4.5469,   0.5435, -16.6250],
E                   [-13.0625, -11.0312,   1.1104,  ...,   6.7070, -14.6406,   6.0664]],
E                  device='cuda:0', dtype=torch.float16),
E               expected=tensor([[ -4.8516,  -1.4551,   3.7480,  ...,   8.5078,   5.3516, -11.5547],
E                   [ -4.4180, -16.3750,  14.4219,  ...,  -6.1055,   8.9141,  -1.5869],
E                   [ -2.9941,  -5.8555,  -0.9629,  ...,  -8.0859,   3.9727,  -4.7578],
E                   ...,
E                   [ 10.6641, -11.0547,   4.5977,  ...,   7.0039,   7.5508,  -7.2461],
E                   [ 13.4688,  10.2422,  -4.3711,  ...,  -4.5469,   0.5435, -16.6250],
E                   [-13.0625, -11.0312,   1.1104,  ...,   6.7070, -14.6406,   6.0664]],
E                  device='cuda:0', dtype=torch.float16),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:45: RuntimeError
____ test_segment_matmul[80-33-slices3-float16-backward-Engine.TORCH-cuda] _____

self = TensorLikePair(
    id=(),
    actual=tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)

    def compare(self) -> None:
        actual, expected = self.actual, self.expected

        self._compare_attributes(actual, expected)
        if any(input.device.type == "meta" for input in (actual, expected)):
            return

        actual, expected = self._equalize_attributes(actual, expected)
>       self._compare_values(actual, expected)

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:706:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:824: in _compare_values
    compare_fn(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = TensorLikePair(
    id=(),
    actual=tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
    ...0.1,
    equal_nan=False,
    check_device=True,
    check_dtype=True,
    check_layout=True,
    check_stride=False,
)
actual = tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
        [ -5.6016,  10.3984,   3.1641,  .....      [  4.1094,  -4.4258,   7.1523,  ...,   6.8906,  -8.5781,   9.8281]],
       device='cuda:0', dtype=torch.float64)
expected = tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
        [ -5.6016,  10.3984,   3.1641,  .....  7.1523,  ...,   6.8906,  -8.5781,   9.8281]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ToCopyBackward0>)

    def _compare_regular_values_close(
        self,
        actual: torch.Tensor,
        expected: torch.Tensor,
        *,
        rtol: float,
        atol: float,
        equal_nan: bool,
        identifier: Optional[Union[str, Callable[[str], str]]] = None,
    ) -> None:
        """Checks if the values of two tensors are close up to a desired tolerance."""
        actual, expected = self._promote_for_comparison(actual, expected)
>       matches = torch.isclose(
            actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan
        )
E       torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.98 GiB (GPU 0; 23.64 GiB total capacity; 19.13 GiB already allocated; 1.87 GiB free; 21.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

../../Accdl/accdl/lib/python3.10/site-packages/torch/testing/_comparison.py:994: OutOfMemoryError

The above exception was the direct cause of the following exception:

K = 80, T = 33
slices = [slice(0, 219777, None), slice(219777, 439554, None), slice(439554, 474471, None), slice(474471, 509388, None), slice(509388, 722309, None), slice(722309, 935230, None), ...]
engine = <Engine.TORCH: 'torch'>, device = 'cuda', phase = 'backward'
dtype = torch.float16

    @pytest.mark.parametrize("device", ["cpu", "cuda"])
    @pytest.mark.parametrize("engine", [Engine.TORCH, Engine.TRITON])
    @pytest.mark.parametrize("phase", ["forward", "backward"])
    @pytest.mark.parametrize("dtype", ["float32", "float16"])
    @pytest.mark.parametrize("slices", [slices0, slices1, AIFB, AM, BGS, DBLP, MUTAG])
    @pytest.mark.parametrize("T", [16, 33])
    @pytest.mark.parametrize("K", [16, 32, 64, 80])
    def test_segment_matmul(K: int, T: int, slices: list, engine: Engine, device: str, phase: str, dtype: str) -> None:
        if engine == Engine.TRITON and device == "cpu":
            pytest.skip("Triton does not support CPU inference")
        if device == "cpu" and dtype == "float16":
            pytest.skip("CPU does not support FP16")
        dtype = getattr(torch, dtype)
        M = sum([s.stop - s.start for s in slices])
        data = torch.randn((M, K), device=device, dtype=dtype)
        types = torch.zeros((M,), device=device, dtype=torch.int)
        for s in slices:
            if s.stop > s.start:
                types[s] = torch.randint(0, T, (s.stop - s.start,), device=device, dtype=torch.int)
        sorted_data, tensor_slice = compact_tensor_types(data, types, device=device)
        other = torch.randn((T, K, K), device=device, dtype=dtype)
        if phase == "forward":
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_ref = torch.zeros((M, K), device=device, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                output_ref[s] = torch.matmul(sorted_data[s], other[t])
            torch.testing.assert_close(output, output_ref, atol=1e-1, rtol=1e-2)
        elif phase == "backward":
            sorted_data.requires_grad = True
            other.requires_grad = True
            output = ops.fasten_segment_matmul(sorted_data, tensor_slice.slices, other, engine, tensor_slice)
            output_grad = torch.randn_like(output)
            output.backward(output_grad)
            sorted_data_grad_ref = torch.zeros_like(data, dtype=dtype)
            other_grad_ref = torch.zeros_like(other, dtype=dtype)
            for i in range(len(tensor_slice)):
                s = tensor_slice.get_slice_from_index(i, is_tensor=False)
                t = tensor_slice.get_type_from_index(i, is_tensor=False)
                sorted_data_grad_ref[s] = torch.matmul(output_grad[s], other[t].t())
                other_grad_ref[t] = torch.matmul(sorted_data[s].t(), output_grad[s])
>           torch.testing.assert_close(sorted_data.grad, sorted_data_grad_ref, atol=1e-1, rtol=1e-2)
E           RuntimeError: Comparing
E
E           TensorLikePair(
E               id=(),
E               actual=tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
E                   [ -5.6016,  10.3984,   3.1641,  ...,  10.6562, -11.4375,   7.8281],
E                   [  2.4062,   2.8320,  20.8594,  ...,   1.5703,  -8.4141,   7.0508],
E                   ...,
E                   [  5.4961,  18.7812,   5.4688,  ...,  -1.3145,   7.2617,  -6.4219],
E                   [  2.4453, -11.5312,  14.5703,  ...,  -0.8130,  -5.2109, -13.6328],
E                   [  4.1094,  -4.4258,   7.1523,  ...,   6.8906,  -8.5781,   9.8281]],
E                  device='cuda:0', dtype=torch.float16),
E               expected=tensor([[-15.9062, -21.3125,  -5.4961,  ..., -16.4531, -13.2969,   3.8398],
E                   [ -5.6016,  10.3984,   3.1641,  ...,  10.6562, -11.4375,   7.8281],
E                   [  2.4062,   2.8320,  20.8594,  ...,   1.5703,  -8.4141,   7.0508],
E                   ...,
E                   [  5.4961,  18.7812,   5.4688,  ...,  -1.3145,   7.2617,  -6.4219],
E                   [  2.4453, -11.5312,  14.5703,  ...,  -0.8130,  -5.2109, -13.6328],
E                   [  4.1094,  -4.4258,   7.1523,  ...,   6.8906,  -8.5781,   9.8281]],
E                  device='cuda:0', dtype=torch.float16, grad_fn=<CopySlices>),
E               rtol=0.01,
E               atol=0.1,
E               equal_nan=False,
E               check_device=True,
E               check_dtype=True,
E               check_layout=True,
E               check_stride=False,
E           )
E
E           resulted in the unexpected exception above. If you are a user and see this message during normal operation please file an issue at https://github.com/pytorch/pytorch/issues. If you are a developer and working on the comparison functions, please except the previous error and raise an expressive `ErrorMeta` instead.

test_ops.py:59: RuntimeError
=========================== short test summary info ============================
FAILED test_ops.py::test_segment_matmul[64-16-slices3-float32-backward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float32-backward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float32-backward-Engine.TRITON-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float16-forward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float16-forward-Engine.TRITON-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float16-backward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-16-slices3-float16-backward-Engine.TRITON-cuda]
FAILED test_ops.py::test_segment_matmul[80-33-slices3-float32-backward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-33-slices3-float32-backward-Engine.TRITON-cuda]
FAILED test_ops.py::test_segment_matmul[80-33-slices3-float16-forward-Engine.TORCH-cuda]
FAILED test_ops.py::test_segment_matmul[80-33-slices3-float16-backward-Engine.TORCH-cuda]
============ 11 failed, 549 passed, 336 skipped in 94.08s (0:01:34) ============
